{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 6: Predicting the fuel efficiency of Vehicles**  \n",
    "Creating Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "cols = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n",
    "df = pd.read_csv('auto-mpg.data', names= cols, na_values= '?', comment='\\t', sep= \" \", skipinitialspace= True)\n",
    "data = df.copy()\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits= 1, test_size= 0.2, random_state= 42)\n",
    "for train_index, test_index in split.split(data, data['Cylinders']):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating feature and target variable\n",
    "data = strat_train_set.drop(\"MPG\", axis=1)\n",
    "data_labels = strat_train_set['MPG'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing origin column\n",
    "def preprocessing_org_column(df):\n",
    "    df['Origin'] = df['Origin'].map({1 : 'India', 2 : 'USA', 3 : 'Germany'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Custom Attribute adder\n",
    "acc_ix, hpower_ix, cyl_ix = 4, 2, 0\n",
    "\n",
    "class CustomAttrAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, acc_on_power = True):\n",
    "        self.acc_on_power = acc_on_power\n",
    "    def fit(self, X, y= None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        acc_on_cyl = X[:, acc_ix] / X[:, cyl_ix]\n",
    "        if self.acc_on_power:\n",
    "            acc_on_power = X[:, acc_ix] / X[:, hpower_ix]\n",
    "            return np.c_[X, acc_on_power, acc_on_cyl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines\n",
    "def num_pipeline_transformer(data):\n",
    "    numerics = ['float64', 'int64']\n",
    "    num_attrs = data.select_dtypes(include= numerics)\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy= 'median')),\n",
    "        ('attr_adder', CustomAttrAdder()),\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ])\n",
    "    return num_attrs, num_pipeline\n",
    "\n",
    "def pipeline_transformer(data):\n",
    "    cat_attrs = ['Origin']\n",
    "    num_attrs, num_pipeline = num_pipeline_transformer(data)\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        ('num', num_pipeline, list(num_attrs)),\n",
    "        ('cat', OneHotEncoder(), cat_attrs)\n",
    "    ])\n",
    "    prepared_data = full_pipeline.fit_transform(data)\n",
    "    return prepared_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From raw to processed data in 2 steps\n",
    "preprocessed_df = preprocessing_org_column(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = pipeline_transformer(preprocessed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32260746,  0.0747988 , -0.5043511 , -0.0145391 ,  0.05835354,\n",
       "        0.54607826,  0.13531964, -0.4808467 ,  0.        ,  1.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data[89]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting and Training Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of samples:  [29.08069379 27.78336755 26.08031176 12.70419279 22.23454159]\n"
     ]
    }
   ],
   "source": [
    "# Testing the prediction\n",
    "sample_data = data.iloc[:5]\n",
    "sample_labels = data_labels.iloc[:5]\n",
    "\n",
    "sample_prepared_data = pipeline_transformer(sample_data)\n",
    "\n",
    "print(\"Prediction of samples: \", lin_reg.predict(sample_prepared_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Values of samples:  [32.0, 31.0, 26.0, 18.0, 26.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual Values of samples: \", list(sample_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9590402225760863"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for evaluation of linear regression model we will use mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mpg_prediction = lin_reg.predict(prepared_data)\n",
    "lin_mse = mean_squared_error(data_labels, mpg_prediction)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree Model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg_predictions = tree_reg.predict(prepared_data)\n",
    "tree_mse = mean_squared_error(data_labels, mpg_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree model is overfitting the data because no model is perfect and it is giving a rmse of 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the tree model using Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, prepared_data, data_labels, scoring= 'neg_mean_squared_error', cv = 10)\n",
    "tree_reg_rmse_scores = np.sqrt(-scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.17440939, 3.0538398 , 2.91981378, 3.20502535, 2.39165215,\n",
       "       3.12664956, 3.53747792, 5.54940875, 4.18673019, 2.54539432])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.369040121177302"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg_rmse_scores.mean() #average error of decision tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.43254597, 3.45157629, 3.6621715 , 2.59652976, 2.48023405,\n",
       "       2.74798115, 3.32524647, 2.42208917, 3.78133275, 2.8573747 ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing cross validation for linear regression\n",
    "scores = cross_val_score(lin_reg, prepared_data, data_labels, scoring= 'neg_mean_squared_error', cv = 10)\n",
    "lin_reg_rmse_scores = np.sqrt(-scores)\n",
    "lin_reg_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0757081793709324"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.567840130160126"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(prepared_data, data_labels)\n",
    "forest_reg_cv_scores = cross_val_score(forest_reg, prepared_data, data_labels, scoring= 'neg_mean_squared_error', cv = 10)\n",
    "forest_reg_rmse_scores = np.sqrt(-forest_reg_cv_scores)\n",
    "forest_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.086591620802784"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vector machine Model\n",
    "from sklearn.svm import SVR \n",
    "\n",
    "svm_reg = SVR(kernel= 'linear')\n",
    "svm_reg.fit(prepared_data, data_labels)\n",
    "svm_cv_scores = cross_val_score(svm_reg, prepared_data, data_labels, scoring= 'neg_mean_squared_error', cv = 10)\n",
    "svm_rmse_scores = np.sqrt(-svm_cv_scores)\n",
    "svm_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model among the 4 turns out to be Random Forest Regressor with a error of 2.56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 7: Hyperparameter Tuning**\n",
    "Using GridSearchCV to find out which set  of parameters works best on random forest regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators' : [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap' : [False], 'n_estimators' : [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, scoring= 'neg_mean_squared_error', return_train_score= True, cv = 10)\n",
    "\n",
    "grid_search.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.481154702111907 {'max_features': 2, 'n_estimators': 3}\n",
      "2.9868111079808957 {'max_features': 2, 'n_estimators': 10}\n",
      "2.9442047385225623 {'max_features': 2, 'n_estimators': 30}\n",
      "3.366089691589925 {'max_features': 4, 'n_estimators': 3}\n",
      "2.9270443727556716 {'max_features': 4, 'n_estimators': 10}\n",
      "2.691173434493788 {'max_features': 4, 'n_estimators': 30}\n",
      "3.0625732198108357 {'max_features': 6, 'n_estimators': 3}\n",
      "2.911565903094848 {'max_features': 6, 'n_estimators': 10}\n",
      "2.7163825625324693 {'max_features': 6, 'n_estimators': 30}\n",
      "2.961816649102916 {'max_features': 8, 'n_estimators': 3}\n",
      "2.7906022950887928 {'max_features': 8, 'n_estimators': 10}\n",
      "2.6783455114192094 {'max_features': 8, 'n_estimators': 30}\n",
      "3.3258270321874335 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "2.955907212616251 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "3.201412763577308 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "2.8327737141047082 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "3.3480972268323663 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "2.7349589086227306 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cv_scores = grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cv_scores['mean_test_score'], cv_scores['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 8: Checking Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15633551, 0.31903765, 0.13853288, 0.17355579, 0.01478748,\n",
       "       0.12676081, 0.02894619, 0.03494111, 0.00243775, 0.00265919,\n",
       "       0.00200565])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = grid_search.best_estimator_.feature_importances_\n",
    "feature_importance #tells the scores of the features i.e. how important each feature is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acc_on_power', 0.028946187601656112),\n",
       " ('acc_on_cyl', 0.03494110623227895),\n",
       " ('Weight', 0.1735557887633897),\n",
       " ('Model Year', 0.12676081257222316),\n",
       " ('Horsepower', 0.1385328824910448),\n",
       " ('Displacement', 0.3190376477829678),\n",
       " ('Cylinders', 0.15633550661155182),\n",
       " ('Acceleration', 0.014787477312617122)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make more sense\n",
    "extra_attrs = [\"acc_on_power\", \"acc_on_cyl\"]\n",
    "numerics = ['float64', 'int64']\n",
    "num_attrs = list(data.select_dtypes(include= numerics))\n",
    "attrs = num_attrs + extra_attrs\n",
    "sorted(zip(attrs, feature_importance), reverse= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 9: Evaluating the entire system on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop('MPG', axis=1)\n",
    "y_test =strat_test_set['MPG'].copy()\n",
    "\n",
    "X_test_preprocessed = preprocessing_org_column(X_test)\n",
    "X_test_prepared = pipeline_transformer(X_test_preprocessed)\n",
    "\n",
    "final_prediction = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_prediction)\n",
    "final_mse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0305646017789436"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 10: Creating a function to cover all the things**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mpg(config, model):\n",
    "\n",
    "    if type(config) == dict:\n",
    "        df = pd.DataFrame(config)\n",
    "    else:\n",
    "        df = config\n",
    "\n",
    "    preproc_df = preprocessing_org_column(df)\n",
    "    prepared_df = pipeline_transformer(preproc_df)\n",
    "    y_pred = model.predict(prepared_df)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.65333333333333"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the model on random sample\n",
    "\n",
    "vehicle_config ={\n",
    "    'Cylinders' : [4, 6, 8],\n",
    "    'Displacement' : [155.0, 160.0, 165.0],\n",
    "    'Horsepower' : [93.0, 130.0, 98.0],\n",
    "    'Weight' : [2500.0, 3150.0, 2600.0],\n",
    "    'Acceleration' : [15.0, 14.0, 16.0],\n",
    "    'Model Year' : [81, 80, 78],\n",
    "    'Origin' : [1, 3, 2]\n",
    "}\n",
    "\n",
    "m = predict_mpg(vehicle_config, final_model)\n",
    "m[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 11: Saving the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the model\n",
    "with open('model.bin', 'wb') as f_out:\n",
    "    pickle.dump(final_model, f_out)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32.56666667, 17.93      , 20.86333333])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the model\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    model = pickle.load(f_in)\n",
    "\n",
    "predict_mpg(vehicle_config, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6daf707862e17be3f0fa751b5d9f5c60e762843d2e0b5ba432bfa461e95d2620"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
